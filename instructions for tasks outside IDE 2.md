Below is a check-list you (or your cloud/IT lead) must complete outside the code-base to stand-up the MVP stack described earlier.  Follow it in order; each line is actionable, and nothing requires you to open the IDE.

‚∏ª

0. Prerequisites (30 min)
	1.	Azure subscription with pay-as-you-go or credits ‚Äì if you don‚Äôt have one, create at https://azure.microsoft.com.
	2.	Owner or Contributor role on that subscription (needed to create resources).
	3.	A Microsoft Entra ID tenant (formerly AAD). Your Azure subscription is automatically linked to one; you‚Äôll use it for SSO.

‚∏ª

1. Request Azure OpenAI access (10 min form + 1-3 days approval)

You cannot skip this ‚Äì the OpenAI resource is gated per tenant.

	‚Ä¢	Go to Azure OpenAI Service > Apply: https://aka.ms/oai/apply.
	‚Ä¢	Use your academic email; choose Education use-case, mention ‚Äúcourse Q&A assistant‚Äù.
	‚Ä¢	Wait for the ‚Äúapproved‚Äù email (typically < 72 h for universities).

‚∏ª

2. Create the core resource group & VNet (5 min)

RG = ta-mvp-rg            # all resources live here
Location = UK South
VNet 10.20.0.0/16
    ‚îú‚îÄ subnet functions   10.20.1.0/24
    ‚îî‚îÄ subnet db          10.20.2.0/24

Portal route ‚ñ∫ Create resource ‚ü∂ Virtual Network; name it ta-mvp-vnet.  Add two sub-nets as above.

‚∏ª

3. Spin up Azure OpenAI in the VNet (~10 min)
	1.	Create ‚ñ∫ Azure OpenAI
	‚Ä¢	Resource group: ta-mvp-rg
	‚Ä¢	Name: ta-mvp-openai
	‚Ä¢	Region: UK South (has GPT-4 Turbo & embeddings)
	2.	Deploy models
	‚Ä¢	In the resource blade ‚Üí Deployments ‚Üí + Create ‚ñ∏ choose:
	‚Ä¢	gpt-4-turbo  (deployment name: gpt4turbo)
	‚Ä¢	text-embedding-3-small (deployment name: embed-small)
	3.	Lock it to private network
	‚Ä¢	Networking ‚ñ∏ Allow access from: Disabled
	‚Ä¢	Add Private Endpoint to ta-mvp-vnet / subnet functions, accepting defaults  .
	‚Ä¢	Azure auto-creates a private DNS zone. Confirm *.openai.azure.com is linked to the VNet.
	4.	Grab credentials
	‚Ä¢	Keys & Endpoint tab ‚Üí copy Key 1 and the endpoint URL (save to password manager ‚Äì you‚Äôll drop them into environment variables later).

‚∏ª

4. Provision Postgres + pgvector (~10 min)
	1.	Create ‚ñ∫ Azure Database for PostgreSQL Flexible Server
	‚Ä¢	Name: ta-mvp-db
	‚Ä¢	Pricing tier: Basic, 1 vCore, 64 GiB storage (‚âà ¬£20 / mo).
	‚Ä¢	Networking: Private access ‚Üí VNet ta-mvp-vnet ‚ñ∏ subnet db.
	2.	Once the server is up, enable pgvector:
	‚Ä¢	Server Parameters ‚ñ∏ add vector to azure.extensions and save  .
	‚Ä¢	Connect via psql and run:

CREATE EXTENSION IF NOT EXISTS vector;
CREATE DATABASE ta_mvp;


	3.	Copy the (private) host name, admin user, and generated password.

‚∏ª

5. Register Entra ID applications for SSO (~10 min)

App	Type	Redirect / Scope	Secrets
ai-ta-frontend	SPA / Public client	https://<staticapp>.azurestaticapps.net/.auth/login/aad/callback	‚Äî
ai-ta-backend	Web API	Expose scope api://<app-id>/Chat.Access	create 1 client secret

Steps:
	1.	Entra ID ‚ñ∏ App registrations ‚ñ∏ New registration (twice).
	2.	For ai-ta-frontend, enable Access tokens (SPA) under Authentication.
	3.	For ai-ta-backend, add Redirect URI https://localhost/auth-oidc/callback (for local testing) and the production Function URL once deployed.
	4.	Note Tenant ID, Client IDs, and the backend Client Secret.

‚∏ª

6. Create Function App + VNet integration (~10 min)
	1.	Create ‚ñ∫ Function App
	‚Ä¢	Name: ta-mvp-fn
	‚Ä¢	Runtime: Python 3.11, Consumption plan.
	‚Ä¢	Region: UK South, same RG.
	2.	Networking ‚ñ∏ VNet integration ‚ñ∏ select subnet functions.
	3.	Configuration ‚ñ∏ Application settings ‚Äì add:

OPENAI_API_KEY   = <Key 1>
OPENAI_ENDPOINT  = https://ta-mvp-openai.openai.azure.com/
OPENAI_GPT_DEPLOYMENT = gpt4turbo
OPENAI_EMBED_DEPLOYMENT = embed-small
PG_HOST          = ta-mvp-db.private.postgres.database.azure.com
PG_DB            = ta_mvp
PG_USER          = <admin_user>
PG_PASSWORD      = <pw>
AAD_TENANT_ID    = <tenant_id>
AAD_CLIENT_ID    = <backend app client id>
AAD_CLIENT_SECRET= <backend secret>

	4.	Identity ‚ñ∏ enable System-assigned managed identity (optional) so you can later swap from key-based to RBAC access.

‚∏ª

7. Spin up Static Web App (~5 min)
	1.	Create ‚ñ∫ Static Web Apps
	‚Ä¢	Name: ta-mvp-ui
	‚Ä¢	Deploy from GitHub repo (or manual upload).
	‚Ä¢	Once built, note the default URL https://<hash>.azurestaticapps.net.
	2.	In the SWA portal ‚ñ∏ Authentication ‚Üí choose Azure Active Directory, point it to ai-ta-frontend app ID.
	3.	Add the SWA URL to the frontend app‚Äôs SPA redirect list (step 5 above).

‚∏ª

8. Set cost guard-rails (5 min)
	‚Ä¢	Cost Management ‚ñ∏ Budgets ‚Äì create a monthly budget of ¬£80 with email alert.
	‚Ä¢	Advisor ‚ñ∏ Recommendations ‚Äì enable cost optimisation alerts.

‚∏ª

9. Smoke-test connectivity (~10 min)
	1.	In App Service Logs enable application logging (filesystem) for Functions.
	2.	Hit /healthz route ‚Äì should return OK.
	3.	Manually run an ingestion HTTP trigger with a tiny markdown file; verify rows appear in chunks table.
	4.	Ask a sample question via /chat route; ensure GPT-4 Turbo responds and citations point to the chunk IDs.

‚∏ª

10. Upload course materials
	‚Ä¢	Use the upload portal (or az storage blob upload) to push PDFs/PPTX.
	‚Ä¢	Confirm embeddings are created and the vector count in Postgres matches chunk count.

‚∏ª

11. Invite pilot users
	1.	Professor logs in via SWA AAD and verifies dashboard shows logs.
	2.	Provide students the SWA URL; they‚Äôll use their institutional OIDC credentials automatically.

‚∏ª

You‚Äôre live üéâ

Latency should be < 1.5 s per query; total burn ‚âà ¬£50 / mo (monitor in Cost Management).  When usage climbs, revisit the Upgrade Path table from the MVP doc.

‚∏ª

Key docs if you get stuck
	‚Ä¢	Private Endpoints for Azure OpenAI ‚Äì step-by-step screenshots  
	‚Ä¢	Enable pgvector on Azure Postgres Flexible Server ‚Äì extension guide  
	‚Ä¢	Model deployment list & regions ‚Äì check availability of GPT-4 Turbo / embedding-3-small   